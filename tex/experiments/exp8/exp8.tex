\subsection*{Overview}
Due to the fact that the end goal for this project is to have a smartphone
application that a user can use to keep track of their calorie measurement,
there are a couple of options in how to achieve this. Firstly, an image can be
taken on the phone and sent to a server to run a classification algorithm.
Secondly, a model can be stored on the phone for computation. Transfer learning was once again used but on a different, smaller architecture called MobileNet \textcite{mobilenet}.

\subsection*{Network Architecture}
The network architecture used for this experiment is MobileNet \textcite{mobilenet}.
A parameter can be set to retrain this model in the code, as mentioned in previous experiments, instead of inception V-3 \textcite{retrainInception}. 
This architecture is designed to be smaller and much more efficient so that
it can be used on smartphones which have less powerful resources available.

Mobilenet is designed for various different use cases on mobile phones such as image classification, landmark recognition, object detection and face attributes.
It is based on "depthwise separable convolutions" whose purpose is the split a convolutional layer into a depthwise convolution and a pointwise convolution (1x1 convolution) \textcite{mobilenet}.
The purpose of the former is to apply "a single filter to each input channel" \textcite{mobilenet} while the latter combines these outputs.
This in turn reduces the computational time.
The first layer of the network is a standard convolutional layer and does not get split up.

Unfortunatley there is a significant decrease in accuracy in using Mobilenet as it is a much thinner model.

\subsection*{Dataset}
The Food 101 dataset \textcite{food101} with added classes was used for this experiment.

\subsection*{Libraries}
Tensorflow and numpy.

\subsection*{Script}
The retrain.py script \textcite{retrainInception} was used, with a different
command paramater.

\begin{lstlisting}
python tensorflow/examples/image_retraining/retrain.py \ --image_dir
~/dataset_directory \ --architecture mobilenet_1.0_224 \
--how_many_training_steps 10000 \ --learning_rate 0.1
\end{lstlisting}

\subsection*{Results}
The final test accuracy of this model came to 50.2\%.

\subsection*{Empirical Analysis}
There was a decrease of 16.1\% in this model to the highest accuracy from
\ref{mobilenet}. This is due to the smaller architecture which is aimed to be faster
and smaller with an expected decrease in accuracy.
