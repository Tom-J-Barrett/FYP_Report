\tocless\subsection{Objective}
For the next experiment, it was decided to use the Food-101 dataset.
An on line tutorial was used to create a dataset in TensorFlow using image directories on disk \parencite{file_dir_code}.
Tutorials used previously were also utilised for this experiment such as \parencite{udemy}.

\begin{table}[h]
\centering
\caption{Using the Food-101 Dataset}
\label{my-label}
\begin{tabular}{|l|p{8cm}|}
\hline
\textbf{Network Architecture} & Similar to \ref{udemy1}            \\ \hline
\textbf{Dataset}              & Food-101 dataset \\ \hline
\textbf{APIs and Libraries}   & TensorFlow                                                         \\ \hline
\end{tabular}
\end{table}

\tocless\subsection{Script}
Figures \ref{lst:readDataset}, \ref{lst:createBatches} and \ref{lst:trainModel3} document the key aspects of the script used in this experiment.
The activities documented include reading in the dataset (Figure \ref{lst:readDataset}), create batches from the dataset (Figure \ref{lst:createBatches}) and training the model (Figure \ref{lst:trainModel3}).

\begin{figure}[h] 
\caption{Read in the Dataset \parencite{file_dir_code}}
\label{lst:readDataset}
\begin{lstlisting}[style=Python]
# Reading the dataset
def read_images(dataset_path, mode, batch_size):
    imagepaths, labels = list(), list()
    # An ID will be given to each sub-folder alphabetically
    label = 0
    classes = sorted(os.walk(dataset_path).__next__()[1])
    # List each sclass
    for c in classes:
        c_dir = os.path.join(dataset_path, c)
           walk = os.walk(c_dir).__next__()
        # Add each image to the training set
        for sample in walk[2]:
            if sample.endswith('.jpg') or sample.endswith('.jpeg'):
                imagepaths.append(os.path.join(c_dir, sample))
                labels.append(label)
        label += 1
\end{lstlisting}
\end{figure}

\begin{figure}[h]
\caption{Create Batches \parencite{file_dir_code}}
\label{lst:createBatches}
\begin{lstlisting}[style=Python]
# Convert to Tensor data strcuture
imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)
labels = tf.convert_to_tensor(labels, dtype=tf.int32)

# Build a queue
image, label = tf.train.slice_input_producer([imagepaths, labels],
                                             shuffle=True)

# Read images
image = tf.read_file(image)
image = tf.image.decode_jpeg(image, channels=CHANNELS)

# Resize images
image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])

# Normalize the images
image = image * 1.0/127.5 - 1.0

# Create batches
X, Y = tf.train.batch([image, label], batch_size=batch_size,
                      capacity=batch_size * 8,
                      num_threads=4)
return X, Y
\end{lstlisting}
\end{figure}

\begin{figure}[h]
\caption{Train the Model \parencite{file_dir_code}}
\label{lst:trainModel3}
\begin{lstlisting}[style=Python]
with tf.Session() as sess:
    sess.run(init)
    tf.train.start_queue_runners()

    #For each step in range, run batch through the model
    for step in range(1, num_steps+1):
        if step % display_step == 0:
            # Run optimization and calculate batch loss and accuracy
            _, loss, acc = sess.run([train_op, loss_op, accuracy])
            print("Step " + str(step) + ", Minibatch Loss= " + \
                  "{:.4f}".format(loss) + ", Training Accuracy= " + \
                  "{:.3f}".format(acc))
        else:
            sess.run(train_op)
\end{lstlisting}
\end{figure}

\tocless\subsection{Results}
The final accuracy for this model was 18.8\% after 5,000 steps.

\tocless\subsection{Analysis}
The poor accuracy of this model is to be expected due to the simple architecture of the network.

\clearpage