\begin{abstract}
Health conditions in the modern age are progressively getting worse with a high percentage of the population being obese.
In order to combat this problem, a dietary assessment smartphone application would be invaluable.
The task of recording one's food intake could be quite tedious and therefore, utilizing computer vision to automatically classify and calculate nutritional value of a user's food image could help to make the process more practical for use.
One approach that could be attempted, is by using Convolutional Neural Networks (CNNs) for the classification of food images.
This is due to the recent high success in using CNNs for image classification.
Retraining of the Inception-V3 model architecture, using TensorFlow, the Food-101 dataset and the ImageNet dataset was carried out, resulting in a classification model.
A Top 1 accuracy of 66.6\% and a Top 5 accuracy of 85.96\% was achieved using a dataset of 108 classes.
It was found that CNNs are very successful in classifying images with over 100 classes and that network fine tuning could result in even better results.
\end{abstract}
