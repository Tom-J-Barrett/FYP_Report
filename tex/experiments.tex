\chapter{Introduction to Using TensorFlow}
The purpose of this chapter is to give an overview of what has been completed to gain understanding of how to create CNNs and also how to work with datasets.
Three experiments are explored in this chapter, the first two of which are tutorials completed as an introduction to TensorFlow and CNNs.
The final experiment explores how to feed datasets from file directories into CNNs.
In addition to these experiments a Deep Learning course was completed on Udacity (an online nanodegree tutorial site) \parencite{udacity}.

\section{Template for Experiments}
The template followed for all experiments in chapters three, four and five is outlined in Table \ref{expTemplate}.

\begin{table}[h]
\centering
\caption{Experiment Template}
\label{expTemplate}
\begin{tabular}{|p{3cm}|p{11cm}|}
\hline
\textbf{Section}   & \textbf{Rationale}                \\ \hline
Objective             & An explanation of the purpose of the experiment along with how it is carried out. \\ \hline
Network Architecture & An explanation of the network architecture used in the experiment. If the architecture has been explained in another experiment, the architecture will only be referenced by name.                       \\ \hline
Dataset              & The dataset used for the experiment, with its source and an overview of its details. A brief mention will be made in following experiments.                       \\ \hline
API's                & Reference to the technologies used as outlined in Chapter 2.                      \\ \hline
Script               & Snippets of the script used for the experiment.                       \\ \hline
Results              & The results acquired from the experiment, usually in the form of a percentage accuracy.                       \\ \hline
Analysis   & States any information gained from the experiment and speculation for the reasoning of the results.                      \\ \hline
\end{tabular}
\end{table}

\section{Udemy Tutorial}
\label{udemy1}
\input{tex/experiments/exp1/exp1.tex}

\section{Udemy Tutorial 2}
\label{udemy2}
\input{tex/experiments/exp2/exp2.tex}

\section{Using the Food 101 dataset}
\label{food101}
\input{tex/experiments/exp3/exp3.tex}

\section{Conclusion}
This chapter has outlined the work done in learning about using TensorFlow to create CNNs and working with datasets.

\chapter{Empirical Studies Part 1}
This chapter consists of experiments which train various TensorFlow models.
There are parameters that can be changed in the code that creates a TensorFlow model based on the Inception-V3 model architecture.
These parameters were changed to see how the model accuracy would be affected.
In addition to this, change in dataset size was explored in relation to model accuracy.


\section{Retrain ImageNet Inception V3 Model}
\label{inception}
\input{tex/experiments/exp4/exp4.tex}

\section{Retrain with Extended Dataset}
\label{extended}
\input{tex/experiments/exp5/exp5.tex}

\section{Retrain with Parameter Tuning}
\label{parameterTuning}
\input{tex/experiments/exp6/exp6.tex}

\section{MobileNet}
\label{mobilenet}
\input{tex/experiments/exp8/exp8.tex}

\section{Food 101 subset}
\label{subset}
\input{tex/experiments/exp13/exp13}

\section{Conclusion}
The focus of this experiment has been to train TensorFlow models using the Inception-V3 architecture under various constraints.
These models have been trained using transfer learning.
The highest accuracy for a model trained using the Food101+ dataset yielded a Top-1 accuracy of 66.6\% and a Top-1 accuracy of 85.96\%.
Alternatively, a model was trained using a subset of the Food101+ dataset.
13 classes from Food101+ were used to benchmark the efficacy of using CNNs against other methods found in the literature review.
This CNN reached a Top-1 accuracy of 92.6\% and a Top-5 accuracy of 100\%.
This exceeded or was comparable to the other methods researched.

\chapter{Empirical Studies Part 2}
The purpose of this chapter is to analyse the models trained previously to gain understanding and applicability to the problem statement.

\section{Sliding Window}
\label{slidingWindow}
\input{tex/experiments/exp7/exp7.tex}

\section{Recursive Refinement}
\label{RR}
\input{tex/experiments/exp9/exp9.tex}

\section{Impact of Background}
\label{background}
\input{tex/experiments/exp10/exp10.tex}

\section{Alternative Test Image}
\label{alternative}
\input{tex/experiments/exp11/exp11.tex}

\section{Analysing Results of Recursive Refinement Further}
\label{rrAnalyse}
\input{tex/experiments/exp16/exp16.tex}

\section{Scaling Down Images}
\label{scale}
\input{tex/experiments/exp12/exp12.tex}

\section{Effect of Colour}
\label{colour}
\input{tex/experiments/exp14/exp14.tex}

\section{Conclusion}
This chapter has analysed the model trained in Chapter 4.
Emphasis was placed on dealing with composite images through a sliding window approach.
Once this had been completed, analysis into the results of the sliding window aproach was carried out by using multiple test images and removing the background from the image.
Recursive refinement on the sliding window approach for images containing grapes was carried out and the results were analysed.
Finally the effect of colour and image size on the classifier was measured.
It was found that different fod types required different levels of features for classification.
% \section{Visualising Images Through the Network}
% \label{visualise}
% \input{tex/experiments/exp15/exp15.tex}

