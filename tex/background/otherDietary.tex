Methods outside of CNNs and SVMs are outlined below.
A summary of the results can be seen in Table \ref{other_dietary_summary} along with SVM method results.

\subsubsection*{Large Scale Learning for Food Image Classification}
\parencite{LSL_2015} proposed a food image recognition system using a Bag of Features model.
This study used over 5000 images separated into 11 classes.

A clustering algorithm was employed on this study before classification.
For the classification step, experiments were carried out using different methods:
\begin{itemize}
	\item{SVM}
	\item{ANN}
	\item{Random Forests}
\end{itemize}

The final accuracy of the system was 78\% \parencite{LSL_2015}.

% % \subsubsection*{Promising Approaches of Computer-supported Dietary Assessment and Management: 
% % Current Research Status and Available Applications}
% % \parencite{arens2015promising}

\subsubsection*{A Personal Assistive System for Nutrient Intake Monitoring}
Similar to other approaches seen thus far, \parencite{personalAssistive} employs the use of the users thumb in the image for size estimation.

Once a photo has been taken by the user with their thumb present, the system segments the food on the plate using shape, colour and texture detectors.
The system then classifies the food type based on these features.

In this paper, it was decided to allow the users to change the prediction by the system.
The thumb of each user is calibrated upon first use of the application so that size estimation can be as accurate a possible \parencite{personalAssistive}.

\subsubsection*{Toward Dietary Assessment via Mobile Phone Video Camera}
Another study into using computer vision for dietary assessment was carried out by \parencite{chen2010toward}. They had a unique medium for the topic by using a video of the dishes in question and extracting frames from these videos to get the food from different angles.

\parencite{chen2010toward} then formed a region of interest in the image, where there were the most food items and extracted colour and image features.
These image features were extracted using Maximally Stable Extremal Regions (MSER), Speeded Up Robust Features (SURF) and Star detector.

This research team also uses k-means clustering to build a bag-of-words model \parencite{chen2010toward}.

The system had results as seen below across 20 categories using five images out of each video taken of the food:
\begin{itemize}
	\item{MSER - 95\%}
	\item{SURF - 90\%}
	\item{STAR - 90\%}
\end{itemize}

% \subsubsection*{Novel Technologies for Assessing Dietary Intake: Evaluating the
% Usability of a Mobile Telephone Food Record Among Adults and Adolescents}
% \parencite{novelTech}


% % \subsubsection*{An Overview of the Technology Assisted Dietary Assessment Project at Purdue University}
% % \parencite{khanna2010overview}

\subsubsection*{Merging dietary assessment with the adolescent lifestyle}
\parencite{schap2014merging} proposed a system used by smart phones which sends an image of a users food to a back end system for computation.

Once this has been completed, the image is segmented, features are extracted from each segment and these segments are classified.
Colour and texture features are used for classification.
The user has the ability to confirm or amend predictions of the food type.

Size estimation is also an important aspect of this system.
In contrast to previous studies, \parencite{snap} uses food type shape and then those shape's geometric properties to estimate size.

This study produced results of 94\% out of 32 test cases.
