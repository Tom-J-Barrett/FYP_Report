There has been a very interesting paper from UC Berkeley focused on using Full Convolutional
Networks for semantic segmentation \parencite{fcn}. Fully Convolutional Networks
(FCN)
do not have any fully connected layers. They are replaced with more filtering
layers. Nvidia Digits have a semantic segmentation implementation based off the
work of this paper.

They took this approach because "feedforward computation and backpropogation are
much more efficient when computer layer-by-layer over an entire image instead of
independently patch-by-patch" \parencite{fcn}. This was also because they
were focused on object detection. Normal classifiers do not work very well when
they are to classify more than one subject in an image and image segmentation
was a way to solve this.

There are a set of steps you can follow to turn a CNN into a FCN for semantic
segmentation as follows ie. change to a convolutional layer from a fully
connected one:
\begin{itemize}
    \item{The size of the filters must be set to the size of the input layers.}
    \item{For every neuron in the fully connected layer, have a filter.}
\end{itemize}

\begin{table}[]
\centering
\caption{FCN Resulys \parencite{fcn}}
\label{fcn}
\begin{tabular}{ll}
                        & FCN  \\
VOC11 mean IU           & 62.7 \\
VOC12 mean IU           & 62.2 \\
PASCAL VOC10 pixel acc. & 67.0 \\
PASCAL VOC10 mean acc.  & 50.7 \\
PASCAL VOC10 mean IU    & 37.8 \\
PASCAL VOC10 f.w. IU    & 52.5
\end{tabular}
\end{table}
