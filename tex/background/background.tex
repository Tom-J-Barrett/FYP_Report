\chapter{Background}
\label{background}

\section{Introduction to Machine Learning}
In \textcite{MLANN}, Machine Learning is defined as "the question of how to
construct computer programs that automatically improve with experience".
Machine Learning has blossomed in recent years with applications across multiple
domains using vastly different paradigms and technologies.

There are many ways in which Machine Learning can be used in the modern world,
many of which are being utilised to great affect.
Some of these applications, are image recognition, natural language processing,
medical diagnosis and many more.
There may be fear that Machine Learning will start to take away many jobs from
humans but this may not be the case. Imagine a doctor, having to diagnose a
patient, a machine can offer suggestions based on very large datasets of what
the diagnosis is. This is not to say that a Machine would be
perscribing patients, but merely act as an assistant to the doctor.

Machine Ethics is a large problem that comes hand in hand with Machine Learning.
There is a very important question of who takes the blame when things go wrong,
that is why I think it is important that we only use Machine Learning to advise
and not to determine but this can be very difficult in a world where, for
example, an autonomous car has to decide between crashing into a vehicle beside
them with an unknown number of people inside or the two children playing in the
street.

One of the most exciting avenues in Machine Learning, in my opinion, is Computer
Vision. Computer Vision can be used in many areas to improve our lives. As
mentioned earlier, autonomous cars are only possible when a machine can
determine what objects are around it. Computer Vision can allow a machine to
recognise skin diseases in an image. The applications are nearly limitless and
that is without taking into account other uses.

\section{Neural Computing}
The main area of my focus for this project is in
Artificial Neural Networks (ANN). This is because I have researched extensively into ConvolutionalÂ Neural Networks which are based on ANN's.
\subsection{Artificial Neural Networks}
An Artificial Neural Network is a bio-inspired system that is used to model the human brain in how it learns from experience.
The ANN uses this model to build a very complex web of connected units called
artificial neurons.
These nuerons are connected by certain weights which determines the processing
capacity of the network and these weights are created by learning a
dataset.(Malachy)
An ANN has a set of inputs that take in a value, sometimes from network outputs
and produce a single result or classification.
While an ANN is bio-inspired from the human brain, there are many elements of
the brain that are not present in ANN and many new elements in ANN that are not
modelled from the human brain.

Before I can talk about Convolution Neural Networks which are vital the image
processing, I will have to talk about the perceptron learning algorithm, the multi
layer percepton, and backpropogation.

\section{Perceptron Learning - Artificial Neuron}
In our Artificial Neural Network a Perecptron is an Artificial Neuron.
It is called an Artifical Neuron because it is a bio-inspired neuron which models
a neuron in the human brain in terms of inputs and output.

In Perceptron learning, we can take two inputs which are put towards an
activation function with a bias attached as seen in \ref{fig:perceptron}.
These inputs are multiplied by the weights that connect the input to the
activation function and depending on the result, the activation function may
fire an output. These inputs are either 1 or -1.

\begin{figure}
     \includegraphics{Perceptron}
     \caption{Perceptron}
     \label{fig:perceptron}
\end{figure}

This Perceptron Learning Rule assumes that there are two sets of instances, a
positive and negative set, and that they are linearly seperable.

A perceptron is trained using supervised learning. When the perceptron
classifies a results, it is told if it is correct or not. If the result is
incorrect, weights are changed in value so that this error can be reduced
\textcite{AI}. 

The one major problem with perceptron learning and that is that it can't solve
the problem if there is not a clear linear separation between the classes. There
is a way in which we can attempt to solve this, through the delta rule. The
delta rule utilizes gradient descent to find the best weight for the training
samples \textcite{MLANN}. We will discuss gradient descent in the next section.

\section{Multi Layered Perceptron}
Multi Layer Perceptrons (MLP) are made up of multiple layers of perceprons connected
together.
Firstly, we have an input layer, followed by one of more hidden layers and then
finally an output layer.
Any Neural Network with more than three hidden layers is categorised as a deep
layer.

The input layer of your network consists of the data you feed into the network
in order to classify it. The input layer passes this data to a hidden layer
whose purpose is to transform this data into something that the output layer can
understand. The output layer normally consists of a class prediction.

Multi Layer Perceptrons are a class of feed forward Artificial Neural Networks.
These means that the output of each perceptron feeds into an input in the next
layer of the network.

There is one large problem with MLP's and this is why Convolutional Neural
Networks (CNN) were created. If you attempting to classify images with an MLP then
each pixel in that image would have to be a separate input. This created a
massive amount of neurons through all the layers and this isn't feasible. CNN's
solve this problem which we will discuss later.

\begin{figure}
    \includegraphics[width=150mm,scale=0.5]{mlp}
     \caption{Multi Layer Perceptron}
     \label{fig:mlp}
\end{figure}

\input{tex/background/gD_bP}

\section{Support Vector Machine}

\section{Convolutional Neural Networks}
Convolutional Neural Networks (CNN's) are essentially a Multi Layered Percetron with a
special structure. CNN's have one major difference from a MLP, they have extra
layer of convolution and pooling.

Figure \ref{fig:XtoRec} show an image that we want to compare against
Figure \ref{fig:XtoComp}.
For humans, it is quite easy to determine that these images are very similar but
for a computer this task is surprisingly difficult.

So what a CNN does, to combat this problem, is to take a small feature from
Figure \ref{fig:XtoRec} and compare it to a subsection of Figure \ref{fig:XtoComp}.
The CNN multiplies the feature and a section of Figure \ref{fig:XtoComp}, adds
up the results and divides by 9. This then gives a decimal value of how likely
it is that the feature is in the part of the image, as seen in Figure
\ref{fig:convoluted}.
This is called filtering. The Convolutional layer is composed of carrying out
this filtering for every single possible location in Figure \ref{fig:XtoComp}.
\begin{figure}
	\caption{Image filtering}
    \label{fig:filter}
      \begin{subfigure}[b]{0.4\textwidth}
          \includegraphics[width=\textwidth]{XtoRec}
          \caption{Image to Classify}
          \label{fig:XtoRec}
      \end{subfigure}
    %
      \begin{subfigure}[b]{0.4\textwidth}
      \includegraphics[width=\textwidth]{XtoComp}
      \caption{Image to Compare}
      \label{fig:XtoComp}
      \end{subfigure}
\end{figure}

\begin{figure}
    \caption{Image Convolution}  
    \begin{subfigure}[b]{0.4\textwidth}
          \includegraphics[width=\textwidth]{ImageFeature}
          \caption{Image Feature to Search}
          \label{fig:feature}
      \end{subfigure}
     %
      \begin{subfigure}[b]{0.4\textwidth}
           \includegraphics[width=\textwidth]{ConvImage}x
           \caption{Convoluted Image}
           \label{fig:convoluted}
      \end{subfigure}
\end{figure}
\begin{figure}
    \includegraphics[width=50mm,scale=0.5]{PooledImage}
    \caption{Pooled Image}
    \label{fig:pooled}
\end{figure}
Next is the Pooling Layer, what this layer does, is it takes the convoluted
layer output, you can use Figure \ref{fig:convoluted} as reference, and from a
user defined size ie. 2x2, gets either the highest decimal value (Max pooling)
or the average value (Mean pooling) and records that as the new value for the
section. This is then applied to the entire image. As we can see in Figure
\ref{fig:pooled} we know have a much smaller image stack in which to classify,
thus making the computation easier.

In between the Convolution and Pooling layer, there is sometimes a Normalization
layer. This Normalization layer creates Rectified Linear Units (RLU's). In other
words, if we take Figure \ref{fig:convoluted}, it changes all minus values to
zero.

\subsubsection{Fully Convolutional Networks}
A Fully Convolutional Network is one that does not have a fully connected layer
and in a fully connected layers place is another convolution layer.

\section{Overview of Machine Vision Approaches to Identification and Classification}
There have been many attempts of identification and classification by many
different researchers over the last number of years. There some approaches that
decouple the two tasks of identification and classification from one another but
mostly, researchers have attempted the two together. Sometimes, by semantic
segmentation and in others simply building a classifier for the image without
taking into account, the need for object identification.

\subsection{Region Based Convolutional Neural Networks}
\input{tex/background/rcnn}
\subsection{Fully Convolutional Neural Networks for Semantic Segmentation}
\input{tex/background/fcn}
\subsection{Image Segmentation}
\input{tex/background/segmentation}
\subsection{Convolutional Neural Networks for Classification}
\input{tex/background/cnn}

\section{Technologies}
\subsection{Tensorflow}
\input{tex/tech/tensorflow}
\subsection{Jupyter}
\input{tex/tech/jupyter}
\subsection{OpenCV}
\input{tex/tech/opencv}

\section{Evaluating the Output}
\input{tex/background/eval}

